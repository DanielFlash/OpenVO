\doxysection{Base\+Trainer\+PPO Class Reference}
\hypertarget{class_base_trainer_p_p_o}{}\label{class_base_trainer_p_p_o}\index{BaseTrainerPPO@{BaseTrainerPPO}}
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_base_trainer_p_p_o_a0fc2773190963a57c41473c62c046eb4}{Base\+Trainer\+PPO}} (\mbox{\hyperlink{class_base_model_p_p_o_actor}{Base\+Model\+PPOActor}} \texorpdfstring{$\ast$}{*}actor\+Model, \mbox{\hyperlink{class_base_model_p_p_o_value}{Base\+Model\+PPOValue}} \texorpdfstring{$\ast$}{*}value\+Model, const double kl\+Coeff, const double v\+Coeff, torch\+::optim\+::\+Adam \texorpdfstring{$\ast$}{*}optimizer\+Adam, torch\+::\+Device \texorpdfstring{$\ast$}{*}device)
\begin{DoxyCompactList}\small\item\em Class initialization. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_base_trainer_p_p_o_a8b5fc092bd1e65780399fbffb755703b}{train\+Step}} (std\+::vector$<$ std\+::vector$<$ int $>$ $>$ state, std\+::vector$<$ std\+::vector$<$ int $>$ $>$ action, std\+::vector$<$ std\+::vector$<$ float $>$ $>$ logits, std\+::vector$<$ std\+::vector$<$ float $>$ $>$ log\+Probs, std\+::vector$<$ std\+::vector$<$ double $>$ $>$ reward)
\begin{DoxyCompactList}\small\item\em Train iteration method. \end{DoxyCompactList}\end{DoxyCompactItemize}
\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\Hypertarget{class_base_trainer_p_p_o_a1e3aefa9c4c4a38d54f13799679a12ca}\label{class_base_trainer_p_p_o_a1e3aefa9c4c4a38d54f13799679a12ca} 
double {\bfseries m\+\_\+kl\+Coeff} \{\}
\begin{DoxyCompactList}\small\item\em Base PPO trainer class. \end{DoxyCompactList}\item 
\Hypertarget{class_base_trainer_p_p_o_a3a92fe53569cbfd8bac5e63bfab9bbd5}\label{class_base_trainer_p_p_o_a3a92fe53569cbfd8bac5e63bfab9bbd5} 
double {\bfseries m\+\_\+v\+Coeff} \{\}
\item 
\Hypertarget{class_base_trainer_p_p_o_af7ef878e576ed709fadc4426862491d6}\label{class_base_trainer_p_p_o_af7ef878e576ed709fadc4426862491d6} 
torch\+::optim\+::\+Adam \texorpdfstring{$\ast$}{*} {\bfseries m\+\_\+optimizer\+Adam}
\item 
\Hypertarget{class_base_trainer_p_p_o_a9f66e9f51da837be454b5a85e8f791ea}\label{class_base_trainer_p_p_o_a9f66e9f51da837be454b5a85e8f791ea} 
\mbox{\hyperlink{class_base_model_p_p_o_actor}{Base\+Model\+PPOActor}} \texorpdfstring{$\ast$}{*} {\bfseries m\+\_\+\+Actor\+Model}
\item 
\Hypertarget{class_base_trainer_p_p_o_ab872139780563064e083dc6cc0fea93b}\label{class_base_trainer_p_p_o_ab872139780563064e083dc6cc0fea93b} 
\mbox{\hyperlink{class_base_model_p_p_o_value}{Base\+Model\+PPOValue}} \texorpdfstring{$\ast$}{*} {\bfseries m\+\_\+\+Value\+Model}
\item 
\Hypertarget{class_base_trainer_p_p_o_a1eaa215d8e55474544ef50bc02a61173}\label{class_base_trainer_p_p_o_a1eaa215d8e55474544ef50bc02a61173} 
torch\+::\+Device \texorpdfstring{$\ast$}{*} {\bfseries m\+\_\+device}
\item 
\Hypertarget{class_base_trainer_p_p_o_a439c088f6bc7138808ac31fbcbc16019}\label{class_base_trainer_p_p_o_a439c088f6bc7138808ac31fbcbc16019} 
bool {\bfseries m\+\_\+cuda\+Enabled}
\end{DoxyCompactItemize}


\doxysubsection{Constructor \& Destructor Documentation}
\Hypertarget{class_base_trainer_p_p_o_a0fc2773190963a57c41473c62c046eb4}\index{BaseTrainerPPO@{BaseTrainerPPO}!BaseTrainerPPO@{BaseTrainerPPO}}
\index{BaseTrainerPPO@{BaseTrainerPPO}!BaseTrainerPPO@{BaseTrainerPPO}}
\doxysubsubsection{\texorpdfstring{BaseTrainerPPO()}{BaseTrainerPPO()}}
{\footnotesize\ttfamily \label{class_base_trainer_p_p_o_a0fc2773190963a57c41473c62c046eb4} 
Base\+Trainer\+PPO\+::\+Base\+Trainer\+PPO (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{class_base_model_p_p_o_actor}{Base\+Model\+PPOActor}} \texorpdfstring{$\ast$}{*}}]{actor\+Model}{, }\item[{\mbox{\hyperlink{class_base_model_p_p_o_value}{Base\+Model\+PPOValue}} \texorpdfstring{$\ast$}{*}}]{value\+Model}{, }\item[{const double}]{kl\+Coeff}{, }\item[{const double}]{v\+Coeff}{, }\item[{torch\+::optim\+::\+Adam \texorpdfstring{$\ast$}{*}}]{optimizer\+Adam}{, }\item[{torch\+::\+Device \texorpdfstring{$\ast$}{*}}]{device}{}\end{DoxyParamCaption})}



Class initialization. 


\begin{DoxyParams}{Parameters}
{\em actor\+Model} & NN actor model\\
\hline
{\em value\+Model} & NN value model\\
\hline
{\em kl\+Coeff} & KL-\/divergence error coefficient\\
\hline
{\em v\+Coeff} & critic error coefficient\\
\hline
{\em optimizer\+Adam} & optimizer\\
\hline
{\em device} & device\+: CPU or GPU\\
\hline
\end{DoxyParams}


\doxysubsection{Member Function Documentation}
\Hypertarget{class_base_trainer_p_p_o_a8b5fc092bd1e65780399fbffb755703b}\index{BaseTrainerPPO@{BaseTrainerPPO}!trainStep@{trainStep}}
\index{trainStep@{trainStep}!BaseTrainerPPO@{BaseTrainerPPO}}
\doxysubsubsection{\texorpdfstring{trainStep()}{trainStep()}}
{\footnotesize\ttfamily \label{class_base_trainer_p_p_o_a8b5fc092bd1e65780399fbffb755703b} 
void Base\+Trainer\+PPO\+::train\+Step (\begin{DoxyParamCaption}\item[{std\+::vector$<$ std\+::vector$<$ int $>$ $>$}]{state}{, }\item[{std\+::vector$<$ std\+::vector$<$ int $>$ $>$}]{action}{, }\item[{std\+::vector$<$ std\+::vector$<$ float $>$ $>$}]{logits}{, }\item[{std\+::vector$<$ std\+::vector$<$ float $>$ $>$}]{log\+Probs}{, }\item[{std\+::vector$<$ std\+::vector$<$ double $>$ $>$}]{reward}{}\end{DoxyParamCaption})}



Train iteration method. 


\begin{DoxyParams}{Parameters}
{\em state} & state\\
\hline
{\em action} & action\\
\hline
{\em logits} & logits\\
\hline
{\em log\+Probs} & log-\/probs\\
\hline
{\em reward} & reward (is cummulative rewards here)\\
\hline
\end{DoxyParams}


The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
Base\+Trainer\+PPO.\+h\item 
Base\+Trainer\+PPO.\+cpp\end{DoxyCompactItemize}

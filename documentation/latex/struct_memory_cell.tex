\doxysection{Memory\+Cell Struct Reference}
\hypertarget{struct_memory_cell}{}\label{struct_memory_cell}\index{MemoryCell@{MemoryCell}}
\doxysubsubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\Hypertarget{struct_memory_cell_aee55501ab61399dde2f06d146cf39c3f}\label{struct_memory_cell_aee55501ab61399dde2f06d146cf39c3f} 
std\+::vector$<$ int $>$ {\bfseries state} \{\}
\begin{DoxyCompactList}\small\item\em Struct for memory cell for reinforcement learning algorithms 
\begin{DoxyParams}{Parameters}
{\em state} & current environment state\\
\hline
{\em action} & current agent action\\
\hline
{\em next\+State} & next environment state\\
\hline
{\em next\+Action} & next agent action\\
\hline
{\em reward} & agent reward\\
\hline
{\em done} & whether episode is done\\
\hline
\end{DoxyParams}
\end{DoxyCompactList}\item 
\Hypertarget{struct_memory_cell_a9fa80a634de814af45df1de27c99aea8}\label{struct_memory_cell_a9fa80a634de814af45df1de27c99aea8} 
std\+::vector$<$ int $>$ {\bfseries action} \{\}
\item 
\Hypertarget{struct_memory_cell_a60def8d214172628569f427e49f58a4f}\label{struct_memory_cell_a60def8d214172628569f427e49f58a4f} 
std\+::vector$<$ int $>$ {\bfseries next\+State} \{\}
\item 
\Hypertarget{struct_memory_cell_aeddd69219148dd30711b0f890d41f862}\label{struct_memory_cell_aeddd69219148dd30711b0f890d41f862} 
std\+::vector$<$ int $>$ {\bfseries next\+Action} \{\}
\item 
\Hypertarget{struct_memory_cell_a5f7fb06b8f4c8d9f041125707eddf4e5}\label{struct_memory_cell_a5f7fb06b8f4c8d9f041125707eddf4e5} 
double {\bfseries reward}
\item 
\Hypertarget{struct_memory_cell_a9ac6fbc1894bbfd28eabc887b797f0b3}\label{struct_memory_cell_a9ac6fbc1894bbfd28eabc887b797f0b3} 
bool {\bfseries done}
\end{DoxyCompactItemize}


The documentation for this struct was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
Type\+VO.\+h\end{DoxyCompactItemize}
